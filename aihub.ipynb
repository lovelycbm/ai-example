{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from model import CropYieldModel, CropDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 및 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset from json_directory/ and images_directory/\n",
      "Found 50 json files\n",
      "Loaded 50 valid samples out of 50 JSON files\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 및 로딩\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = CropDataset('json_directory/', 'images_directory/', transform=transform)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델, 손실 함수, 옵티마이저 초기화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CropYieldModel().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 169413.9688\n",
      "Epoch [2/100], Loss: 125347.8203\n",
      "Epoch [3/100], Loss: 81046.8281\n",
      "Epoch [4/100], Loss: 29065.8242\n",
      "Epoch [5/100], Loss: 48622.3125\n",
      "Epoch [6/100], Loss: 36061.4961\n",
      "Epoch [7/100], Loss: 16742.9258\n",
      "Epoch [8/100], Loss: 43301.5312\n",
      "Epoch [9/100], Loss: 45336.9883\n",
      "Epoch [10/100], Loss: 28670.4512\n",
      "Epoch [11/100], Loss: 18483.6270\n",
      "Epoch [12/100], Loss: 13587.4111\n",
      "Epoch [13/100], Loss: 3603.4604\n",
      "Epoch [14/100], Loss: 3281.8430\n",
      "Epoch [15/100], Loss: 25226.0508\n",
      "Epoch [16/100], Loss: 13711.6445\n",
      "Epoch [17/100], Loss: 10452.7627\n",
      "Epoch [18/100], Loss: 5933.5132\n",
      "Epoch [19/100], Loss: 10463.6396\n",
      "Epoch [20/100], Loss: 3053.0608\n",
      "Epoch [21/100], Loss: 8879.2979\n",
      "Epoch [22/100], Loss: 9926.3721\n",
      "Epoch [23/100], Loss: 10743.1289\n",
      "Epoch [24/100], Loss: 2891.8062\n",
      "Epoch [25/100], Loss: 3155.7275\n",
      "Epoch [26/100], Loss: 4928.4565\n",
      "Epoch [27/100], Loss: 4344.0381\n",
      "Epoch [28/100], Loss: 3334.7830\n",
      "Epoch [29/100], Loss: 6898.8774\n",
      "Epoch [30/100], Loss: 3582.7842\n",
      "Epoch [31/100], Loss: 4463.2129\n",
      "Epoch [32/100], Loss: 3251.5767\n",
      "Epoch [33/100], Loss: 4052.5300\n",
      "Epoch [34/100], Loss: 2213.2175\n",
      "Epoch [35/100], Loss: 2485.3894\n",
      "Epoch [36/100], Loss: 2565.5496\n",
      "Epoch [37/100], Loss: 3248.8943\n",
      "Epoch [38/100], Loss: 2366.6790\n",
      "Epoch [39/100], Loss: 2493.5942\n",
      "Epoch [40/100], Loss: 3484.6550\n",
      "Epoch [41/100], Loss: 1987.5243\n",
      "Epoch [42/100], Loss: 3145.0603\n",
      "Epoch [43/100], Loss: 2889.0081\n",
      "Epoch [44/100], Loss: 4059.1384\n",
      "Epoch [45/100], Loss: 4379.0327\n",
      "Epoch [46/100], Loss: 4102.7554\n",
      "Epoch [47/100], Loss: 4040.2395\n",
      "Epoch [48/100], Loss: 4418.3193\n",
      "Epoch [49/100], Loss: 2928.0210\n",
      "Epoch [50/100], Loss: 2151.4548\n",
      "Epoch [51/100], Loss: 3096.7312\n",
      "Epoch [52/100], Loss: 3900.2712\n",
      "Epoch [53/100], Loss: 2687.7393\n",
      "Epoch [54/100], Loss: 2856.4817\n",
      "Epoch [55/100], Loss: 1636.3771\n",
      "Epoch [56/100], Loss: 2714.4712\n",
      "Epoch [57/100], Loss: 3095.8984\n",
      "Epoch [58/100], Loss: 2391.8264\n",
      "Epoch [59/100], Loss: 1520.0229\n",
      "Epoch [60/100], Loss: 2803.5786\n",
      "Epoch [61/100], Loss: 2187.1716\n",
      "Epoch [62/100], Loss: 2739.1750\n",
      "Epoch [63/100], Loss: 2078.6733\n",
      "Epoch [64/100], Loss: 2326.8125\n",
      "Epoch [65/100], Loss: 2750.1111\n",
      "Epoch [66/100], Loss: 1573.3188\n",
      "Epoch [67/100], Loss: 1586.6851\n",
      "Epoch [68/100], Loss: 2657.3184\n",
      "Epoch [69/100], Loss: 868.7040\n",
      "Epoch [70/100], Loss: 2122.3667\n",
      "Epoch [71/100], Loss: 1568.6224\n",
      "Epoch [72/100], Loss: 1398.2996\n",
      "Epoch [73/100], Loss: 1376.4664\n",
      "Epoch [74/100], Loss: 1595.7018\n",
      "Epoch [75/100], Loss: 1453.4341\n",
      "Epoch [76/100], Loss: 2505.2576\n",
      "Epoch [77/100], Loss: 1743.0767\n",
      "Epoch [78/100], Loss: 1807.2856\n",
      "Epoch [79/100], Loss: 3837.8889\n",
      "Epoch [80/100], Loss: 1909.0466\n",
      "Epoch [81/100], Loss: 1443.3293\n",
      "Epoch [82/100], Loss: 2006.2294\n",
      "Epoch [83/100], Loss: 843.1882\n",
      "Epoch [84/100], Loss: 1665.6458\n",
      "Epoch [85/100], Loss: 2149.1255\n",
      "Epoch [86/100], Loss: 1408.4469\n",
      "Epoch [87/100], Loss: 1984.4868\n",
      "Epoch [88/100], Loss: 1146.0591\n",
      "Epoch [89/100], Loss: 798.2638\n",
      "Epoch [90/100], Loss: 1521.4460\n",
      "Epoch [91/100], Loss: 922.0781\n",
      "Epoch [92/100], Loss: 688.1413\n",
      "Epoch [93/100], Loss: 1884.7600\n",
      "Epoch [94/100], Loss: 686.2986\n",
      "Epoch [95/100], Loss: 943.3167\n",
      "Epoch [96/100], Loss: 1319.4827\n",
      "Epoch [97/100], Loss: 1407.0472\n",
      "Epoch [98/100], Loss: 1236.2719\n",
      "Epoch [99/100], Loss: 727.7421\n",
      "Epoch [100/100], Loss: 941.1123\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, (images, features, labels) in enumerate(dataloader):\n",
    "        images = images.to(device)\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images, features)\n",
    "        loss = criterion(outputs, labels.unsqueeze(1))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'crop_yield_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Yield: 279.58\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    new_image_id = \"0120200824MS02N000070\"  # 예시 ID\n",
    "    \n",
    "    # 새 JSON 파일 읽기\n",
    "    with open(f\"json_directory/{new_image_id}.json\", 'r', encoding='utf-8-sig') as f:\n",
    "        new_data = json.load(f)\n",
    "    \n",
    "    # 새 이미지 파일 찾기 (jpg만)\n",
    "    new_image_jpg = f\"images_directory/{new_image_id}.jpg\"\n",
    "    \n",
    "    if os.path.exists(new_image_jpg):\n",
    "        new_image_path = new_image_jpg\n",
    "    else:\n",
    "        raise FileNotFoundError(f\" 이미지 {new_image_id} 파일이 없습니다.\")\n",
    "    \n",
    "    new_image = transform(Image.open(new_image_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    new_features = torch.tensor([[\n",
    "        new_data['GSD'],\n",
    "        new_data['LONG'],\n",
    "        new_data['LAT'],\n",
    "        new_data['GROWTH_1'],\n",
    "        new_data['GROWTH_2']\n",
    "    ]], dtype=torch.float32).to(device)\n",
    "    \n",
    "    prediction = model(new_image, new_features)\n",
    "    print(f'예측된 수확량 : {prediction.item():.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
